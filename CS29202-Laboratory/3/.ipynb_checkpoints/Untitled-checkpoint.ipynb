{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf7d20fd-f366-4227-a66a-f6d0a9aabcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL.ImageShow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6ed65ba-ade1-49f5-baf8-9be68bb6dbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925 446\n"
     ]
    }
   ],
   "source": [
    "with Image.open(\"test.png\") as im:\n",
    "    \n",
    "    height = im.size[0]\n",
    "    width = im.size[1]\n",
    "    (left, upper, right, lower) = (height/2 - 50, width/2 -50, height/2 +50, width/2+50)\n",
    "    im_crop = im.crop((left, upper, right, lower))\n",
    "#     PIL.ImageShow.show(im_crop)\n",
    "    obj = BlurImage(20)\n",
    "    arr = np.array(im)\n",
    "#     print(arr)\n",
    "    PIL.ImageShow.show(obj.__call__(im))\n",
    "    print(height,width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68888490-08a3-4b8f-a514-b02d41e24b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =(5,6)\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3870ab4b-b756-4683-9fa7-bda19381d4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('annotations.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "#     print(f\"result: {result}\")\n",
    "#     print(isinstance(result, dict))\n",
    "    break\n",
    "\n",
    "print(len(json_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c64ec2a7-cb79-4bc9-8a14-e54098f3d942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imgs/0.jpg'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['img_fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1870d683-d337-45a3-a1e3-e73054ca0026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_fn': 'imgs/0.jpg',\n",
       " 'png_ann_fn': 'pngs/0.png',\n",
       " 'img_id': '4495',\n",
       " 'bboxes': [{'bbox': [189.82, 111.18, 72.06, 67.41],\n",
       "   'category': 'tv',\n",
       "   'category_id': 72},\n",
       "  {'bbox': [4.19, 148.57, 150.17, 178.69],\n",
       "   'category': 'chair',\n",
       "   'category_id': 62},\n",
       "  {'bbox': [201.58, 198.92, 296.3, 176.08],\n",
       "   'category': 'couch',\n",
       "   'category_id': 63},\n",
       "  {'bbox': [0.0, 235.0, 500.0, 140.0],\n",
       "   'category': 'carpet',\n",
       "   'category_id': 101},\n",
       "  {'bbox': [145.0, 167.0, 153.0, 82.0],\n",
       "   'category': 'shelf',\n",
       "   'category_id': 156},\n",
       "  {'bbox': [0.0, 0.0, 255.0, 257.0],\n",
       "   'category': 'wall-concrete',\n",
       "   'category_id': 172},\n",
       "  {'bbox': [249.0, 0.0, 251.0, 341.0],\n",
       "   'category': 'wall-other',\n",
       "   'category_id': 173},\n",
       "  {'bbox': [4.0, 111.0, 494.0, 264.0],\n",
       "   'category': 'stuff-other',\n",
       "   'category_id': 183}]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "44b84263-48e9-4bf6-a799-2646bb9eeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = json.loads(json_list[1])\n",
    "image = Image.open(row['img_fn'])\n",
    "image = np.array(image)\n",
    "image = image.transpose((2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "266110f4-f7f3-4ba2-b576-e1548f91f167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 640, 429)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "59eae367-daf3-4d1d-b57d-673aa81c2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_png_ann = Image.open(row['png_ann_fn'])\n",
    "gt_png_ann = np.array(gt_png_ann)\n",
    "gt_png_ann = gt_png_ann.reshape((1,gt_png_ann.shape[0],gt_png_ann.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9ff586c4-f8f8-4c2f-a9e2-2b2d58423292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 640, 429)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_png_ann.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0055d905-6920-4f1c-8fed-ce264d9234d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[105, 105, 105, ..., 168, 168, 168],\n",
       "        [105, 105, 105, ..., 168, 168, 168],\n",
       "        [105, 105, 105, ..., 168, 168, 168],\n",
       "        ...,\n",
       "        [116, 116, 116, ..., 116, 116, 116],\n",
       "        [116, 116, 116, ..., 116, 116, 116],\n",
       "        [116, 116, 116, ..., 116, 116, 116]]], dtype=uint8)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_png_ann.reshape((1,gt_png_ann.shape[0],gt_png_ann.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "83f2a6a1-6c78-46ad-b2f7-e2ba22173d83",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-20579b87905e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgt_png_ann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "gt_png_ann.size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "13e04004-454d-4014-982b-45fc67259a29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gt_bboxes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-0f552e2366ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgt_bboxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gt_bboxes' is not defined"
     ]
    }
   ],
   "source": [
    "gt_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e83c7c04-2896-4b83-8f64-dd176db97c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(row['bboxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "26dd23dc-cbe2-4686-99bc-636e46bb942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_bboxes = []\n",
    "for bbox in row['bboxes']:\n",
    "    array = [bbox['category_id'],bbox['bbox'][0],bbox['bbox'][1],bbox['bbox'][2],bbox['bbox'][3]]\n",
    "    gt_bboxes.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0ca5e596-f149-4ab1-bc20-8992925832be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 104.36, 144.98, 158.4, 275.66],\n",
       " [41, 199.57, 346.23, 68.15, 80.51],\n",
       " [1, 66.51, 210.49, 7.93, 13.59],\n",
       " [1, 42.75, 210.38, 7.46, 14.08],\n",
       " [1, 38.62, 213.35, 4.48, 10.47],\n",
       " [1, 80.2, 208.0, 7.09, 16.77],\n",
       " [105, 140.0, 203.0, 92.0, 153.0],\n",
       " [106, 0.0, 0.0, 123.0, 109.0],\n",
       " [117, 0.0, 405.0, 429.0, 235.0],\n",
       " [124, 50.0, 187.0, 40.0, 32.0],\n",
       " [140, 0.0, 192.0, 429.0, 231.0],\n",
       " [166, 20.0, 181.0, 108.0, 44.0],\n",
       " [169, 0.0, 0.0, 429.0, 239.0],\n",
       " [172, 235.0, 208.0, 194.0, 36.0],\n",
       " [183, 39.0, 145.0, 229.0, 282.0]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f7a95c3d-e586-4c3d-a448-c8f7b92fc585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c236ac58-6399-466d-90bd-c985fb191c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d5029919-9301-4fd1-8af9-6af72cc0f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "\n",
    "class BlurImage(object):\n",
    "    '''\n",
    "        Applies Gaussian Blur on the image.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, radius):\n",
    "        '''\n",
    "            Arguments:\n",
    "            radius (int): radius to blur\n",
    "        '''\n",
    "\n",
    "        self.radius = radius\n",
    "        \n",
    "\n",
    "    def __call__(self, image):\n",
    "        '''\n",
    "            Arguments:\n",
    "            image (numpy array or PIL Image)\n",
    "\n",
    "            Returns:\n",
    "            image (numpy array or PIL Image)\n",
    "        '''\n",
    "        if (type(image).__module__ == np.__name__):\n",
    "            image = Image.fromarray(image)\n",
    "                    \n",
    "        return image.filter(ImageFilter.GaussianBlur(radius = self.radius))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3e8f527f-52ee-4e2f-81f4-8e7361d1788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925 446\n"
     ]
    }
   ],
   "source": [
    "with Image.open(\"test.png\") as im:\n",
    "    \n",
    "    height = im.size[0]\n",
    "    width = im.size[1]\n",
    "    (left, upper, right, lower) = (height/2 - 50, width/2 -50, height/2 +50, width/2+50)\n",
    "    im_crop = im.crop((left, upper, right, lower))\n",
    "#     PIL.ImageShow.show(im_crop)\n",
    "    obj = BlurImage(20)\n",
    "    arr = np.array(im)\n",
    "#     print(arr)\n",
    "    PIL.ImageShow.show(obj(im))\n",
    "    print(height,width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "02162172-ef05-46b1-9c23-1a959167283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "def plot_visualization(image,bboxes,output_folder): # Write the required arguments\n",
    "\n",
    "  # The function should plot the predicted segmentation maps and the bounding boxes on the images and save them.\n",
    "  # Tip: keep the dimensions of the output image less than 800 to avoid RAM crashes.\n",
    "    counter = 0\n",
    "    for bbox in bboxes:\n",
    "        if(counter>=3):\n",
    "            break\n",
    "        counter = counter + 1\n",
    "        (x0,y0,x1,y1) = bbox[1:]\n",
    "        img1 = ImageDraw.Draw(image)  \n",
    "        img1.rectangle((x0,y0,x1,y1))\n",
    "        img1.text((x1, y1), str(bbox[0]), font=ImageFont.truetype(\"arial\"))\n",
    "\n",
    "    image.save(output_folder+'/output',\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "453598db-a19b-4ab6-96d2-ec8814121658",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Image.open(\"test.png\") as im:\n",
    "    bboxes = [[1, 104.36, 144.98, 158.4, 275.66],\n",
    "     [41, 199.57, 346.23, 68.15, 80.51],\n",
    "     [1, 66.51, 210.49, 7.93, 13.59]]\n",
    "    plot_visualization(im,bboxes,\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "277c43d0-ee8a-472d-8e05-fc1237964fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_package.data.transforms import crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d62960e-0b08-47f0-889c-550fbdaeb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_package.data.transforms import CropImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b3eb449-feb0-449f-8f88-908557d4d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = CropImage((100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37bf82f5-7d0b-4288-a194-4e655bce9f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446, 925, 4)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-69fd45c1610c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     print(arr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mImageShow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'obj' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image,ImageShow\n",
    "with Image.open(\"test.png\") as im:\n",
    "    \n",
    "    height = im.size[0]\n",
    "    width = im.size[1]\n",
    "    (left, upper, right, lower) = (height/2 - 50, width/2 -50, height/2 +50, width/2+50)\n",
    "    im_crop = im.crop((left, upper, right, lower))\n",
    "#     PIL.ImageShow.show(im_crop)\n",
    "    arr = np.array(im)\n",
    "    print(arr.shape)\n",
    "#     print(arr)\n",
    "    ImageShow.show(obj(im))\n",
    "    print(height,width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee62f40-b01b-4ae4-94d9-219924a3f87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59080aca-c515-4a1c-ae54-3e651ee518b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfabfbc-d6d3-4d22-843a-136a3a4ff219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6a8e9f-9b56-446f-b008-79779ac08d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfjuror/anaconda3/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from my_package.model import InstanceSegmentationModel\n",
    "from my_package.data import Dataset\n",
    "from my_package.analysis import plot_visualization\n",
    "from my_package.data.transforms import FlipImage, RescaleImage, BlurImage, CropImage, RotateImage\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def experiment(annotation_file, segmentor, transforms, outputs):\n",
    "    '''\n",
    "        Function to perform the desired experiments\n",
    "\n",
    "        Arguments:\n",
    "        annotation_file: Path to annotation file\n",
    "        segmentor: The image segmentor\n",
    "        transforms: List of transformation classes\n",
    "        outputs: path of the output folder to store the images\n",
    "    '''\n",
    "\n",
    "    #Create the instance of the dataset.\n",
    "    exp_dataset = Dataset(annotation_file,transforms)\n",
    "\n",
    "    #Iterate over all data items.\n",
    "    #Get the predictions from the segmentor.\n",
    "    for data_row in exp_dataset:\n",
    "        pred_boxes, pred_masks, pred_class, pred_score = segmentor(data_row['image'])\n",
    "        #Draw the segmentation maps on the image and save them.\n",
    "        plot_visualization(data_row['image'],pred_boxes,pred_masks,pred_class,'./output')\n",
    "\n",
    "    #Do the required analysis experiments.\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    segmentor = InstanceSegmentationModel()\n",
    "    experiment('./data/annotations.jsonl', segmentor, [FlipImage(), BlurImage(2)], None) # Sample arguments to call experiment()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df72885d-cfa2-421d-b039-93cb7f124132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image,ImageShow\n",
    "image1 = Image.open('test.png','r')\n",
    "image2 = Image.open('logo.png','r')\n",
    "mask = np.ones_like(image1)[:,:,0]\n",
    "# im = Image.composite(image1, image2,mask)\n",
    "# image2.putalpha(128)\n",
    "image1.paste(image2)\n",
    "image1.save('testt','PNG')\n",
    "ImageShow.show(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd32b759-bf47-4584-84a5-4ba930713e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(925, 446)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72c872f8-a7c9-4183-9e71-9fc22760bec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(446, 925)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "806a8b73-29b3-4031-a26e-114ca07aa7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f27eebc-8ea7-4c51-806a-30677b9b40cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 500, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image,ImageShow\n",
    "image1 = Image.open('./data/imgs/0.jpg','r')\n",
    "image1 = np.array(image1)\n",
    "image1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7dc98-cde8-44ad-b4b5-c2ce7937ad97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
